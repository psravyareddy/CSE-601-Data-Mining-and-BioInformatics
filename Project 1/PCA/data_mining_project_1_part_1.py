# -*- coding: utf-8 -*-
"""Data Mining Project 1 - Part 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17QMeY9xpoOqSY3jWR4P8As3FV1vPv24P

## Project 1 - Part 1 - Dimensionality Reduction

Team members: Sai Hari Charan, Shravya Pentaparthi, Hemant Koti <br>

In this notebook, we will use dimensionality reduction on three biomedical data files and visualize the data points. <br>
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import pandas as pd
import argparse

import numpy as np
from numpy import mean
from numpy import cov

import scipy.linalg as la
import matplotlib.pyplot as plt

import random
from random import randint

import sklearn as sklearn
from sklearn.decomposition import TruncatedSVD
from sklearn.manifold import TSNE

def parse_args():
    parser = argparse.ArgumentParser(description="Data Mining Project 1 - Dimensionality Reduction and Association Analysis.")
    parser.add_argument("--filepath", type=str, default="pca_a.txt", help="Path to the PCA datasets")
    args = parser.parse_args()
    return args

figsize = (15,10)

"""#### 1. Implement PCA and then run it on three data file (pca_a.txt, pca_b.txt, pca_c.txt) to get the two-dimensional data points. For each dataset, draw the data points with a scatter plot, and color them according to their disease names."""

def PCA(file_name):
    df = pd.read_csv(file_name, sep='\t', header=None)
    print('Data \n', df)
    y = df[df.columns[-1]]
    attributes = df.drop(df.columns[-1], axis=1)

    mean = attributes.mean(skipna=True)
    X_bar = attributes - mean

    covariance_matrix = np.cov(np.transpose(X_bar))
    eigvals, eigvecs = la.eig(covariance_matrix)
    #print("\nEigen values of a given matrix are \n",eigvals)
    #print("\nCorresponding eigen vectors are \n", eigvecs)

    index = np.argsort(eigvals)[::-1][:2]
    eigvals = eigvals[index]
    eigvecs = eigvecs[:, index]
    #print("\nEigen values after sorting are \n", eigvals)
    #print("\nEigen vectors after sorting are \n", eigvecs)

    pca = np.dot(X_bar, eigvecs)
    result = pd.DataFrame(list(pca[:, 0]), columns=['PCA1'])
    result['PCA2'] = list(pca[:, 1])
    result['Y'] = y
    #print("\nResult \n", result)

    return result

# Code: https://stackoverflow.com/a/50218895/6379722
def visualizepca(title, result):
    labels = result.Y.unique()
    nrof_labels = len(pd.unique(result['Y']))
    color = ["#"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])
             for i in range(nrof_labels)]

    fig, ax = plt.subplots(figsize=figsize)
    label_color = dict(zip(labels, color))
    print(label_color)
    label_set = set()
    for index, row in result.iterrows():
      if row['Y'] in label_set:
        ax.scatter(x = row['PCA1'], y = row['PCA2'], color = label_color[row['Y']], s= 75)
      else:
        label_set.add( row['Y'])
        ax.scatter(x = row['PCA1'], y = row['PCA2'], color = label_color[row['Y']], label = row['Y'], s= 75)

    plt.title(title)
    plt.legend()
    plt.show()

"""#### 2. Apply existing packages to run SVD and t-SNE algorithms (Do not need to implement them by yourself) and get the two-dimensional data points. Visualize the data points of the two algorithms on the three datasets in the same way as the visualization of PCA results in step 2.

Implementation of SVD using existing libraries
"""

def SVD(filename):
    df = pd.read_csv(filename, sep='\t', header=None)
    y = df[df.columns[-1]]
    attributes = df.drop(df.columns[-1], axis=1)
    svd = TruncatedSVD(n_components=2)
    svd.fit(attributes)
    result = svd.transform(attributes)
    result = pd.DataFrame(result, columns=['Feature1','Feature2'])
    result['classification'] = y
    print('Result \n', result)
    return result

# Code: https://stackoverflow.com/a/50218895/6379722
def visualizesvd(title, result):
  labels=result.classification.unique()
  nrof_labels = len(pd.unique(result['classification']))
  color = ["#"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])
            for i in range(nrof_labels)]
  fig, ax = plt.subplots(figsize=figsize)
  label_color = dict(zip(pd.unique(result['classification']),color))
  print(label_color)
  label_set = set()
  for index, row in result.iterrows():
      if row['classification'] in label_set:
        ax.scatter(x = row['Feature1'], y = row['Feature2'], color = label_color[row['classification']], s= 75)
      else:
        label_set.add(row['classification'])
        ax.scatter(x = row['Feature1'], y = row['Feature2'], color = label_color[row['classification']], label = row['classification'], s= 75)

  plt.title(title)
  plt.legend()
  plt.show()

"""t-SNE implementaion using existing Libraries"""
def tSNE(filename):
    df = pd.read_csv(filename, sep='\t', header=None)
    y = df[df.columns[-1]]
    attributes = df.drop(df.columns[-1], axis=1)
    #tsne = TSNE(n_components=2) 
    #result = tsne.fit_transform(attributes)
    tsne = TSNE(n_components=2,init="pca",n_iter=1000) 
    result = tsne.fit_transform(attributes)
    #result=tsne.fit_transform(attributes)
    result = pd.DataFrame(result, columns=['Feature1','Feature2'])
    result['classification'] = y
    print('Result \n', result)
    return result

# Code: https://stackoverflow.com/a/50218895/6379722
def visualizetsne(title, result):
  labels = result.classification.unique()
  nrof_labels = len(pd.unique(result['classification']))
  color = ["#"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])
            for i in range(nrof_labels)]
  fig, ax = plt.subplots(figsize=figsize)
  label_color = dict(zip(pd.unique(result['classification']),color))
  print(label_color)
  label_set = set()
  for index, row in result.iterrows():
      if row['classification'] in label_set:
        ax.scatter(x = row['Feature1'], y = row['Feature2'], color = label_color[row['classification']], s= 75)
      else:
        label_set.add(row['classification'])
        ax.scatter(x = row['Feature1'], y = row['Feature2'], color = label_color[row['classification']], label = row['classification'], s= 75)

  plt.title(title)
  plt.legend()
  plt.show()


def main():
    
    args = parse_args()
    
    visualizepca('PCA visualization for PCA '+(args.filepath.split('/')[-1]), PCA(args.filepath))
  
    visualizesvd('Singular Value Decomposition for PCA '+(args.filepath.split('/')[-1]), SVD(args.filepath))

    visualizetsne('t-SNE Visualization for PCA '+(args.filepath.split('/')[-1]), tSNE(args.filepath))
    
  
if __name__ == "__main__":
  main()

"""

References

Code
1. https://www.analyticsvidhya.com/blog/2019/08/5-applications-singular-value-decomposition-svd-data-science/
2. https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b
3. https://stackoverflow.com/a/31008839
4. https://stackoverflow.com/a/50218895/6379722

Readings
1. https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/ <br>
2. https://towardsdatascience.com/principal-component-analysis-pca-from-scratch-in-python-7f3e2a540c51
3. https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/

"""